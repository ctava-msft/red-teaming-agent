# Project Overview: Humana Red Teaming Agent

## Summary

A comprehensive Python-based solution for automated AI red teaming using **PyRIT** (Python Risk Identification Tool) and **Azure AI Foundry**. This project enables security teams to proactively identify safety and security risks in generative AI systems.

## Key Features

âœ… **Automated Red Teaming Scans**
- Test AI systems against 100+ attack objectives per risk category
- Support for 20+ attack strategies (jailbreaks, encoding attacks, etc.)
- Coverage for violence, sexual content, hate/unfairness, and self-harm categories

âœ… **Flexible Target Support**
- Simple callback functions
- OpenAI chat completion protocol
- Direct model configuration scanning
- PyRIT prompt targets

âœ… **Comprehensive Reporting**
- Attack Success Rate (ASR) metrics
- Risk category breakdown
- Attack complexity analysis
- JSON and text report formats

âœ… **Azure Integration**
- Secure authentication with Managed Identity or Azure CLI
- Results logging to Azure AI Foundry
- Storage account integration for compliance

âœ… **Enterprise-Ready**
- Structured logging
- Configuration management
- Unit tests included
- Security best practices

## Project Structure

```
humana-red-teaming-agent/
â”œâ”€â”€ ğŸ“‚ src/                          # Core application code
â”‚   â”œâ”€â”€ red_team_agent.py            # Main Red Teaming Agent
â”‚   â”œâ”€â”€ config_manager.py            # Configuration management
â”‚   â”œâ”€â”€ auth.py                      # Azure authentication
â”‚   â”œâ”€â”€ logger.py                    # Logging utilities
â”‚   â””â”€â”€ results_processor.py         # Results analysis
â”‚
â”œâ”€â”€ ğŸ“‚ examples/                     # Usage examples
â”‚   â”œâ”€â”€ simple_callback_example.py   # Basic callback example
â”‚   â”œâ”€â”€ advanced_callback_example.py # OpenAI protocol example
â”‚   â””â”€â”€ model_config_example.py      # Model scanning example
â”‚
â”œâ”€â”€ ğŸ“‚ config/                       # Configuration files
â”‚   â””â”€â”€ config.yaml                  # Application settings
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                        # Unit tests
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_auth.py
â”‚   â””â”€â”€ test_results_processor.py
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                         # Documentation
â”‚   â””â”€â”€ AZURE_SETUP.md               # Azure setup guide
â”‚
â”œâ”€â”€ ğŸ“‚ outputs/                      # Scan results (gitignored)
â”œâ”€â”€ ğŸ“‚ logs/                         # Log files (gitignored)
â”‚
â”œâ”€â”€ ğŸ“„ README.md                     # Main documentation
â”œâ”€â”€ ğŸ“„ QUICKSTART.md                 # Quick start guide
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ“„ requirements-dev.txt          # Development dependencies
â”œâ”€â”€ ğŸ“„ pyproject.toml                # Project metadata
â”œâ”€â”€ ğŸ“„ .env.example                  # Environment template
â””â”€â”€ ğŸ“„ .gitignore                    # Git ignore rules
```

## Technology Stack

### Core Dependencies
- **azure-ai-evaluation[redteam]** - PyRIT integration for red teaming
- **azure-identity** - Azure authentication (Managed Identity/CLI)
- **azure-ai-projects** - Azure AI Foundry integration
- **python-dotenv** - Environment variable management
- **pyyaml** - Configuration file parsing

### Development Tools
- **pytest** - Unit testing framework
- **black** - Code formatting
- **flake8** - Linting
- **mypy** - Type checking

### Python Version
- **Required**: Python 3.10, 3.11, or 3.12
- **Not Supported**: Python 3.9 or earlier

## Workflow

```
1. Configure
   â”œâ”€â”€ Set up Azure AI Foundry project
   â”œâ”€â”€ Configure .env with credentials
   â””â”€â”€ Customize config.yaml settings

2. Initialize Agent
   â”œâ”€â”€ Load configuration
   â”œâ”€â”€ Authenticate with Azure
   â””â”€â”€ Initialize PyRIT agent

3. Define Target
   â”œâ”€â”€ Simple callback function, OR
   â”œâ”€â”€ OpenAI protocol callback, OR
   â””â”€â”€ Model configuration

4. Run Scan
   â”œâ”€â”€ Generate attack objectives
   â”œâ”€â”€ Apply attack strategies
   â”œâ”€â”€ Probe target system
   â””â”€â”€ Evaluate responses

5. Analyze Results
   â”œâ”€â”€ Calculate Attack Success Rate (ASR)
   â”œâ”€â”€ Generate summary reports
   â”œâ”€â”€ Identify high-risk findings
   â””â”€â”€ Log to Azure AI Foundry
```

## Use Cases

### 1. Pre-Production Security Testing
Test AI applications before deployment to identify potential vulnerabilities.

### 2. Model Selection
Compare safety characteristics of different models during evaluation phase.

### 3. Continuous Monitoring
Run periodic scans to ensure ongoing compliance and safety.

### 4. Compliance Reporting
Generate detailed reports for security audits and compliance requirements.

### 5. Incident Investigation
Analyze specific scenarios or prompts that may have caused issues.

## Security & Compliance

### Authentication Methods
- âœ… **Managed Identity** (Recommended for production in Azure)
- âœ… **Azure CLI** (Recommended for local development)
- âœ… **Service Principal** (For CI/CD pipelines)
- âŒ **Never** hardcode credentials

### Data Protection
- All credentials stored in environment variables
- Results can be logged to Azure storage with encryption
- RBAC controls for access management
- Compliance with organization security policies

### Ethical Use
- âš ï¸ Only test systems you own or have permission to test
- âš ï¸ Human expert review required for high-risk findings
- âš ï¸ Follow responsible AI practices

## Quick Start Commands

```powershell
# Setup
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install "azure-ai-evaluation[redteam]" --pre

# Configure
cp .env.example .env
# Edit .env with your Azure credentials

# Run first scan
python examples\simple_callback_example.py

# Run all examples
python examples\simple_callback_example.py
python examples\advanced_callback_example.py
python examples\model_config_example.py

# Run tests
pytest tests/
```

## Support & Resources

### Documentation
- [README.md](README.md) - Complete documentation
- [QUICKSTART.md](QUICKSTART.md) - Get started in 10 minutes
- [docs/AZURE_SETUP.md](docs/AZURE_SETUP.md) - Azure configuration guide

### Microsoft Resources
- [Azure AI Red Teaming Agent](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/ai-red-teaming-agent)
- [PyRIT on GitHub](https://github.com/Azure/PyRIT)
- [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/)

### Contact
- Humana AI Security Team
- Internal Slack: #ai-security
- Support Portal: [link]

## Roadmap

### Current (v0.1.0)
- âœ… Basic red teaming capabilities
- âœ… PyRIT integration
- âœ… Azure AI Foundry support
- âœ… Multiple target types
- âœ… Comprehensive reporting

### Planned (v0.2.0)
- ğŸ”„ Web UI for results visualization
- ğŸ”„ Custom attack strategy definitions
- ğŸ”„ Automated remediation suggestions
- ğŸ”„ Integration with CI/CD pipelines
- ğŸ”„ Enhanced metrics and dashboards

### Future
- ğŸ“‹ Multi-language support
- ğŸ“‹ Additional risk categories
- ğŸ“‹ Real-time monitoring
- ğŸ“‹ Collaborative red teaming features

## Contributing

This is an internal Humana project. For contributions:
1. Create a feature branch
2. Follow code style guidelines (use `black` for formatting)
3. Add unit tests
4. Submit pull request for review

## License & Usage

- **Internal Use Only** - Humana proprietary
- Follow organization's security and compliance policies
- Do not share credentials or sensitive results externally

## Version History

### v0.1.0 (Current)
- Initial release
- Core red teaming functionality
- PyRIT and Azure AI Foundry integration
- Example applications
- Documentation and tests

---

**Last Updated**: November 10, 2025
**Maintained By**: Humana AI Security Team
**Status**: Active Development
